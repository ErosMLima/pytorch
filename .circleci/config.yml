# WARNING: DO NOT EDIT THIS FILE DIRECTLY!!!
# See the README.md in this directory.

# IMPORTANT: To update Docker image version, please follow
# the instructions at
# https://github.com/pytorch/pytorch/wiki/Docker-image-build-on-CircleCI

version: 2.1

parameters:
  run_binary_tests:
    type: boolean
    default: false
  run_build:
    type: boolean
    default: true

executors:
  windows-with-nvidia-gpu:
    machine:
      resource_class: windows.gpu.nvidia.medium
      image: windows-server-2019-nvidia:stable
      shell: bash.exe

  windows-xlarge-cpu-with-nvidia-cuda:
    machine:
      resource_class: windows.xlarge
      image: windows-server-2019-vs2019:stable
      shell: bash.exe

  windows-medium-cpu-with-nvidia-cuda:
    machine:
      resource_class: windows.medium
      image: windows-server-2019-vs2019:stable
      shell: bash.exe
commands:

  calculate_docker_image_tag:
    description: "Calculates the docker image tag"
    steps:
      - run:
          name: "Calculate docker image hash"
          command: |
            DOCKER_TAG=$(git rev-parse HEAD:.circleci/docker)
            echo "DOCKER_TAG=${DOCKER_TAG}" >> "${BASH_ENV}"

  designate_upload_channel:
    description: "inserts the correct upload channel into ${BASH_ENV}"
    steps:
      - run:
          name: adding UPLOAD_CHANNEL to BASH_ENV
          command: |
            our_upload_channel=nightly
            # On tags upload to test instead
            if [[ -n "${CIRCLE_TAG}" ]]; then
              our_upload_channel=test
            fi
            echo "export UPLOAD_CHANNEL=${our_upload_channel}" >> ${BASH_ENV}

  # This system setup script is meant to run before the CI-related scripts, e.g.,
  # installing Git client, checking out code, setting up CI env, and
  # building/testing.
  setup_linux_system_environment:
    steps:
      - run:
          name: Set Up System Environment
          no_output_timeout: "1h"
          command: .circleci/scripts/setup_linux_system_environment.sh

  setup_ci_environment:
    steps:
      - run:
          name: Set Up CI Environment After attach_workspace
          no_output_timeout: "1h"
          command: .circleci/scripts/setup_ci_environment.sh

  brew_update:
    description: "Update Homebrew and install base formulae"
    steps:
      - run:
          name: Update Homebrew
          no_output_timeout: "10m"
          command: |
            set -ex

            # Update repositories manually.
            # Running `brew update` produces a comparison between the
            # current checkout and the updated checkout, which takes a
            # very long time because the existing checkout is 2y old.
            for path in $(find /usr/local/Homebrew -type d -name .git)
            do
            cd $path/..
            git fetch --depth=1 origin
            git reset --hard origin/master
            done

            export HOMEBREW_NO_AUTO_UPDATE=1

            # Install expect and moreutils so that we can call `unbuffer` and `ts`.
            # moreutils installs a `parallel` executable by default, which conflicts
            # with the executable from the GNU `parallel`, so we must unlink GNU
            # `parallel` first, and relink it afterwards.
            brew unlink parallel
            brew install moreutils
            brew link parallel --overwrite
            brew install expect

  brew_install:
    description: "Install Homebrew formulae"
    parameters:
      formulae:
        type: string
        default: ""
    steps:
      - run:
          name: Install << parameters.formulae >>
          no_output_timeout: "10m"
          command: |
            set -ex
            export HOMEBREW_NO_AUTO_UPDATE=1
            brew install << parameters.formulae >>

  run_brew_for_macos_build:
    steps:
      - brew_update
      - brew_install:
          formulae: libomp

  run_brew_for_ios_build:
    steps:
      - brew_update
      - brew_install:
          formulae: libtool

  optional_merge_target_branch:
    steps:
      - run:
          name: (Optional) Merge target branch
          no_output_timeout: "10m"
          command: |
            if [[ -n "$CIRCLE_PULL_REQUEST" && "$CIRCLE_BRANCH" != "nightly" ]]; then
              PR_NUM=$(basename $CIRCLE_PULL_REQUEST)
              CIRCLE_PR_BASE_BRANCH=$(curl -s https://api.github.com/repos/$CIRCLE_PROJECT_USERNAME/$CIRCLE_PROJECT_REPONAME/pulls/$PR_NUM | jq -r '.base.ref')
              if [[ "${BUILD_ENVIRONMENT}" == *"xla"* || "${BUILD_ENVIRONMENT}" == *"gcc5"* ]] ; then
                set -x
                git config --global user.email "circleci.ossci@gmail.com"
                git config --global user.name "CircleCI"
                git config remote.origin.url https://github.com/pytorch/pytorch.git
                git config --add remote.origin.fetch +refs/heads/master:refs/remotes/origin/master
                git fetch --tags --progress https://github.com/pytorch/pytorch.git +refs/heads/master:refs/remotes/origin/master --depth=100 --quiet
                # PRs generated from ghstack has format CIRCLE_PR_BASE_BRANCH=gh/xxx/1234/base
                if [[ "${CIRCLE_PR_BASE_BRANCH}" == "gh/"* ]]; then
                  CIRCLE_PR_BASE_BRANCH=master
                fi
                export GIT_MERGE_TARGET=`git log -n 1 --pretty=format:"%H" origin/$CIRCLE_PR_BASE_BRANCH`
                echo "GIT_MERGE_TARGET: " ${GIT_MERGE_TARGET}
                export GIT_COMMIT=${CIRCLE_SHA1}
                echo "GIT_COMMIT: " ${GIT_COMMIT}
                git checkout -f ${GIT_COMMIT}
                git reset --hard ${GIT_COMMIT}
                git merge --allow-unrelated-histories --no-edit --no-ff ${GIT_MERGE_TARGET}
                echo "Merged $CIRCLE_PR_BASE_BRANCH branch before building in environment $BUILD_ENVIRONMENT"
                set +x
              else
                echo "No need to merge with $CIRCLE_PR_BASE_BRANCH, skipping..."
              fi
            else
              echo "This is not a pull request, skipping..."
            fi

  upload_binary_size_for_android_build:
    description: "Upload binary size data for Android build"
    parameters:
      build_type:
        type: string
        default: ""
      artifacts:
        type: string
        default: ""
    steps:
      - run:
          name: "Binary Size - Install Dependencies"
          no_output_timeout: "5m"
          command: |
            retry () {
              $* || (sleep 1 && $*) || (sleep 2 && $*) || (sleep 4 && $*) || (sleep 8 && $*)
            }
            retry pip3 install requests
      - run:
          name: "Binary Size - Untar Artifacts"
          no_output_timeout: "5m"
          command: |
            # The artifact file is created inside docker container, which contains the result binaries.
            # Now unpackage it into the project folder. The subsequent script will scan project folder
            # to locate result binaries and report their sizes.
            # If artifact file is not provided it assumes that the project folder has been mounted in
            # the docker during build and already contains the result binaries, so this step can be skipped.
            export ARTIFACTS="<< parameters.artifacts >>"
            if [ -n "${ARTIFACTS}" ]; then
              tar xf "${ARTIFACTS}" -C ~/project
            fi
      - run:
          name: "Binary Size - Upload << parameters.build_type >>"
          no_output_timeout: "5m"
          command: |
            cd ~/project
            export ANDROID_BUILD_TYPE="<< parameters.build_type >>"
            export COMMIT_TIME=$(git log --max-count=1 --format=%ct || echo 0)
            python3 .circleci/scripts/upload_binary_size_to_scuba.py android

##############################################################################
# Binary build (nightlies nightly build) defaults
# The binary builds use the docker executor b/c at time of writing the machine
# executor is limited to only two cores and is painfully slow (4.5+ hours per
# GPU build). But the docker executor cannot be run with --runtime=nvidia, and
# so the binary test/upload jobs must run on a machine executor. The package
# built in the build job is persisted to the workspace, which the test jobs
# expect. The test jobs just run a few quick smoke tests (very similar to the
# second-round-user-facing smoke tests above) and then upload the binaries to
# their final locations. The upload part requires credentials that should only
# be available to org-members.
#
# binary_checkout MUST be run before other commands here. This is because the
# other commands are written in .circleci/scripts/*.sh , so the pytorch source
# code must be downloaded on the machine before they can be run. We cannot
# inline all the code into this file, since that would cause the yaml size to
# explode past 4 MB (all the code in the command section is just copy-pasted to
# everywhere in the .circleci/config.yml file where it appears).
##############################################################################

# Checks out the Pytorch and Builder repos (always both of them), and places
# them in the right place depending on what executor we're running on. We curl
# our .sh file from the interweb to avoid yaml size bloat. Note that many jobs
# do not need both the pytorch and builder repos, so this is a little wasteful
# (smoke tests and upload jobs do not need the pytorch repo).
binary_checkout: &binary_checkout
  name: Checkout pytorch/builder repo
  command: .circleci/scripts/binary_checkout.sh

# Parses circleci arguments in a consistent way, essentially routing to the
# correct pythonXgccXcudaXos build we want
binary_populate_env: &binary_populate_env
  name: Set up binary env variables
  command: .circleci/scripts/binary_populate_env.sh

binary_install_miniconda: &binary_install_miniconda
  name: Install miniconda
  no_output_timeout: "1h"
  command: .circleci/scripts/binary_install_miniconda.sh

# This section is used in the binary_test and smoke_test jobs. It expects
# 'binary_populate_env' to have populated /home/circleci/project/env and it
# expects another section to populate /home/circleci/project/ci_test_script.sh
# with the code to run in the docker
binary_run_in_docker: &binary_run_in_docker
  name: Run in docker
  # This step only runs on circleci linux machine executors that themselves
  # need to start docker images
  command: .circleci/scripts/binary_run_in_docker.sh
##############################################################################
# Build parameters
##############################################################################
pytorch_params: &pytorch_params
  parameters:
    build_environment:
      type: string
      default: ""
    docker_image:
      type: string
      default: ""
    resource_class:
      type: string
      default: "large"
    use_cuda_docker_runtime:
      type: string
      default: ""
    build_only:
      type: string
      default: ""
  environment:
    BUILD_ENVIRONMENT: << parameters.build_environment >>
    DOCKER_IMAGE: << parameters.docker_image >>
    USE_CUDA_DOCKER_RUNTIME: << parameters.use_cuda_docker_runtime >>
    BUILD_ONLY: << parameters.build_only >>
  resource_class: << parameters.resource_class >>

pytorch_ios_params: &pytorch_ios_params
  parameters:
    build_environment:
      type: string
      default: ""
    ios_arch:
      type: string
      default: ""
    ios_platform:
      type: string
      default: ""
    op_list:
      type: string
      default: ""
    use_metal:
      type: string
      default: "0"
    lite_interpreter:
      type: string
      default: "0"
  environment:
    BUILD_ENVIRONMENT: << parameters.build_environment >>
    IOS_ARCH: << parameters.ios_arch >>
    IOS_PLATFORM: << parameters.ios_platform >>
    SELECTED_OP_LIST: << parameters.op_list >>
    USE_PYTORCH_METAL: << parameters.use_metal >>
    BUILD_LITE_INTERPRETER: << parameters.lite_interpreter >>

pytorch_windows_params: &pytorch_windows_params
  parameters:
    executor:
      type: string
      default: "windows-xlarge-cpu-with-nvidia-cuda"
    build_environment:
      type: string
      default: ""
    test_name:
      type: string
      default: ""
    cuda_version:
      type: string
      default: "10.1"
    python_version:
      type: string
      default: "3.6"
    vc_version:
      type: string
      default: "14.16"
    vc_year:
      type: string
      default: "2019"
    vc_product:
      type: string
      default: "BuildTools"
    use_cuda:
      type: string
      default: ""
  environment:
    BUILD_ENVIRONMENT: <<parameters.build_environment>>
    SCCACHE_BUCKET: "ossci-compiler-cache"
    CUDA_VERSION: <<parameters.cuda_version>>
    PYTHON_VERSION: <<parameters.python_version>>
    VC_VERSION: <<parameters.vc_version>>
    VC_YEAR: <<parameters.vc_year>>
    VC_PRODUCT: <<parameters.vc_product>>
    USE_CUDA: <<parameters.use_cuda>>
    TORCH_CUDA_ARCH_LIST: "7.5"
    JOB_BASE_NAME: <<parameters.test_name>>
    JOB_EXECUTOR: <<parameters.executor>>
binary_linux_build_params: &binary_linux_build_params
  parameters:
    build_environment:
      type: string
      default: ""
    docker_image:
      type: string
      default: ""
    libtorch_variant:
      type: string
      default: ""
    resource_class:
      type: string
      default: "2xlarge+"
  environment:
    BUILD_ENVIRONMENT: << parameters.build_environment >>
    LIBTORCH_VARIANT: << parameters.libtorch_variant >>
    ANACONDA_USER: pytorch
  resource_class: << parameters.resource_class >>
  docker:
    - image: << parameters.docker_image >>

binary_linux_test_upload_params: &binary_linux_test_upload_params
  parameters:
    build_environment:
      type: string
      default: ""
    docker_image:
      type: string
      default: ""
    libtorch_variant:
      type: string
      default: ""
    resource_class:
      type: string
      default: "medium"
    use_cuda_docker_runtime:
      type: string
      default: ""
  environment:
    BUILD_ENVIRONMENT: << parameters.build_environment >>
    DOCKER_IMAGE: << parameters.docker_image >>
    USE_CUDA_DOCKER_RUNTIME: << parameters.use_cuda_docker_runtime >>
    LIBTORCH_VARIANT: << parameters.libtorch_variant >>
  resource_class: << parameters.resource_class >>

binary_mac_params: &binary_mac_params
  parameters:
    build_environment:
      type: string
      default: ""
  environment:
    BUILD_ENVIRONMENT: << parameters.build_environment >>

binary_windows_params: &binary_windows_params
  parameters:
    build_environment:
      type: string
      default: ""
    executor:
      type: string
      default: "windows-xlarge-cpu-with-nvidia-cuda"
  environment:
    BUILD_ENVIRONMENT: << parameters.build_environment >>
    BUILD_FOR_SYSTEM: windows
    JOB_EXECUTOR: <<parameters.executor>>

promote_common: &promote_common
  docker:
    - image: pytorch/release
  parameters:
    package_name:
      description: "package name to promote"
      type: string
      default: ""
  environment:
    PACKAGE_NAME: << parameters.package_name >>
    ANACONDA_API_TOKEN: ${CONDA_PYTORCHBOT_TOKEN}
    AWS_ACCESS_KEY_ID: ${PYTORCH_BINARY_AWS_ACCESS_KEY_ID}
    AWS_SECRET_ACCESS_KEY: ${PYTORCH_BINARY_AWS_SECRET_ACCESS_KEY}
##############################################################################
# Job specs
##############################################################################
  binary_linux_build:
    <<: *binary_linux_build_params
    steps:
    - checkout
    - calculate_docker_image_tag
    - run:
        <<: *binary_checkout
    - run:
        <<: *binary_populate_env
    - run:
        name: Build
        no_output_timeout: "1h"
        command: |
            source "/pytorch/.circleci/scripts/binary_linux_build.sh"
            # Preserve build log
            if [ -f /pytorch/build/.ninja_log ]; then
              cp /pytorch/build/.ninja_log /final_pkgs
            fi
    - run:
        name: Output binary sizes
        no_output_timeout: "1m"
        command: |
            ls -lah /final_pkgs
    - run:
        name: save binary size
        no_output_timeout: "5m"
        command: |
            source /env
            cd /pytorch && export COMMIT_TIME=$(git log --max-count=1 --format=%ct || echo 0)
            python3 -mpip install requests && \
            SCRIBE_GRAPHQL_ACCESS_TOKEN=${SCRIBE_GRAPHQL_ACCESS_TOKEN} \
            python3 /pytorch/.circleci/scripts/upload_binary_size_to_scuba.py || exit 0
    - persist_to_workspace:
        root: /
        paths: final_pkgs

    - store_artifacts:
        path: /final_pkgs

    # This should really just be another step of the binary_linux_build job above.
    # This isn't possible right now b/c the build job uses the docker executor
    # (otherwise they'd be really really slow) but this one uses the macine
    # executor (b/c we have to run the docker with --runtime=nvidia and we can't do
    # that on the docker executor)
  binary_linux_test:
    <<: *binary_linux_test_upload_params
    machine:
        image: ubuntu-1604:202007-01
    steps:
    # See Note [Workspace for CircleCI scripts] in job-specs-setup.yml
    - checkout
    - attach_workspace:
        at: /home/circleci/project
    - setup_linux_system_environment
    - setup_ci_environment
    - run:
        <<: *binary_checkout
    - run:
        <<: *binary_populate_env
    - run:
        name: Prepare test code
        no_output_timeout: "1h"
        command: .circleci/scripts/binary_linux_test.sh
    - run:
        <<: *binary_run_in_docker

  binary_upload:
    parameters:
      package_type:
        type: string
        description: "What type of package we are uploading (eg. wheel, libtorch, conda)"
        default: "wheel"
      upload_subfolder:
        type: string
        description: "What subfolder to put our package into (eg. cpu, cudaX.Y, etc.)"
        default: "cpu"
    docker:
      - image: continuumio/miniconda3
    environment:
      - DRY_RUN: disabled
      - PACKAGE_TYPE: "<< parameters.package_type >>"
      - UPLOAD_SUBFOLDER: "<< parameters.upload_subfolder >>"
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - checkout
      - designate_upload_channel
      - run:
          name: Install dependencies
          no_output_timeout: "1h"
          command: |
            conda install -yq anaconda-client
            pip install -q awscli
      - run:
          name: Do upload
          no_output_timeout: "1h"
          command: |
            AWS_ACCESS_KEY_ID="${PYTORCH_BINARY_AWS_ACCESS_KEY_ID}" \
              AWS_SECRET_ACCESS_KEY="${PYTORCH_BINARY_AWS_SECRET_ACCESS_KEY}" \
              ANACONDA_API_TOKEN="${CONDA_PYTORCHBOT_TOKEN}" \
              .circleci/scripts/binary_upload.sh

  # Nighlty build smoke tests defaults
  # These are the second-round smoke tests. These make sure that the binaries are
  # correct from a user perspective, testing that they exist from the cloud are
  # are runnable. Note that the pytorch repo is never cloned into these jobs
  ##############################################################################
  smoke_linux_test:
    <<: *binary_linux_test_upload_params
    machine:
      image: ubuntu-1604:202007-01
    steps:
    - checkout
    - calculate_docker_image_tag
    - setup_linux_system_environment
    - setup_ci_environment
    - run:
        <<: *binary_checkout
    - run:
        <<: *binary_populate_env
    - run:
        name: Test
        no_output_timeout: "1h"
        command: |
          set -ex
          cat >/home/circleci/project/ci_test_script.sh \<<EOL
          # The following code will be executed inside Docker container
          set -eux -o pipefail
          /builder/smoke_test.sh
          # The above code will be executed inside Docker container
          EOL
    - run:
        <<: *binary_run_in_docker

  smoke_mac_test:
    <<: *binary_linux_test_upload_params
    macos:
      xcode: "12.0"
    steps:
      - checkout
      - run:
          <<: *binary_checkout
      - run:
          <<: *binary_populate_env
      - brew_update
      - run:
          <<: *binary_install_miniconda
      - run:
          name: Build
          no_output_timeout: "1h"
          command: |
            set -ex
            source "/Users/distiller/project/env"
            export "PATH=$workdir/miniconda/bin:$PATH"
            # TODO unbuffer and ts this, but it breaks cause miniconda overwrites
            # tclsh. But unbuffer and ts aren't that important so they're just
            # disabled for now
            ./builder/smoke_test.sh

  binary_mac_build:
    <<: *binary_mac_params
    macos:
      xcode: "12.0"
    steps:
    # See Note [Workspace for CircleCI scripts] in job-specs-setup.yml
    - checkout
    - run:
        <<: *binary_checkout
    - run:
        <<: *binary_populate_env
    - brew_update
    - run:
        <<: *binary_install_miniconda

    - run:
        name: Build
        no_output_timeout: "90m"
        command: |
          # Do not set -u here; there is some problem with CircleCI
          # variable expansion with PROMPT_COMMAND
          set -ex -o pipefail
          script="/Users/distiller/project/pytorch/.circleci/scripts/binary_macos_build.sh"
          cat "$script"
          source "$script"

    - run:
        name: Test
        no_output_timeout: "1h"
        command: |
          # Do not set -u here; there is some problem with CircleCI
          # variable expansion with PROMPT_COMMAND
          set -ex -o pipefail
          script="/Users/distiller/project/pytorch/.circleci/scripts/binary_macos_test.sh"
          cat "$script"
          source "$script"

    - persist_to_workspace:
        root: /Users/distiller/project
        paths: final_pkgs

    - store_artifacts:
        path: /Users/distiller/project/final_pkgs

  binary_macos_arm64_build:
    <<: *binary_mac_params
    macos:
      xcode: "12.3.0"
    steps:
    # See Note [Workspace for CircleCI scripts] in job-specs-setup.yml
    - checkout
    - run:
        <<: *binary_checkout
    - run:
        <<: *binary_populate_env
    - brew_update
    - run:
        <<: *binary_install_miniconda

    - run:
        name: Build
        no_output_timeout: "90m"
        command: |
          # Do not set -u here; there is some problem with CircleCI
          # variable expansion with PROMPT_COMMAND
          set -ex -o pipefail
          export CROSS_COMPILE_ARM64=1
          script="/Users/distiller/project/pytorch/.circleci/scripts/binary_macos_build.sh"
          cat "$script"
          source "$script"

    - persist_to_workspace:
        root: /Users/distiller/project
        paths: final_pkgs

    - store_artifacts:
        path: /Users/distiller/project/final_pkgs


  binary_ios_build:
    <<: *pytorch_ios_params
    macos:
      xcode: "12.0"
    steps:
    - attach_workspace:
        at: ~/workspace
    - checkout
    - run_brew_for_ios_build
    - run:
        name: Build
        no_output_timeout: "1h"
        command: |
          script="/Users/distiller/project/.circleci/scripts/binary_ios_build.sh"
          cat "$script"
          source "$script"
    - run:
        name: Test
        no_output_timeout: "30m"
        command: |
          script="/Users/distiller/project/.circleci/scripts/binary_ios_test.sh"
          cat "$script"
          source "$script"
    - persist_to_workspace:
        root: /Users/distiller/workspace/
        paths: ios

  binary_ios_upload:
    <<: *pytorch_ios_params
    macos:
      xcode: "12.0"
    steps:
    - attach_workspace:
        at: ~/workspace
    - checkout
    - run_brew_for_ios_build
    - run:
        name: Upload
        no_output_timeout: "1h"
        command: |
          script="/Users/distiller/project/.circleci/scripts/binary_ios_upload.sh"
          cat "$script"
          source "$script"

  binary_windows_build:
    <<: *binary_windows_params
    parameters:
      build_environment:
        type: string
        default: ""
      executor:
        type: string
        default: "windows-xlarge-cpu-with-nvidia-cuda"
    executor: <<parameters.executor>>
    steps:
    # See Note [Workspace for CircleCI scripts] in job-specs-setup.yml
    - checkout
    - run:
        <<: *binary_checkout
    - run:
        <<: *binary_populate_env
    - run:
        name: Build
        no_output_timeout: "1h"
        command: |
          set -eux -o pipefail
          script="/c/w/p/.circleci/scripts/binary_windows_build.sh"
          cat "$script"
          source "$script"
    - persist_to_workspace:
        root: "C:/w"
        paths: final_pkgs
    - store_artifacts:
        path: C:/w/final_pkgs

  binary_windows_test:
    <<: *binary_windows_params
    parameters:
      build_environment:
        type: string
        default: ""
      executor:
        type: string
        default: "windows-medium-cpu-with-nvidia-cuda"
    executor: <<parameters.executor>>
    steps:
    - checkout
    - attach_workspace:
        at: c:/users/circleci/project
    - run:
        <<: *binary_checkout
    - run:
        <<: *binary_populate_env
    - run:
        name: Test
        no_output_timeout: "1h"
        command: |
          set -eux -o pipefail
          script="/c/w/p/.circleci/scripts/binary_windows_test.sh"
          cat "$script"
          source "$script"

  smoke_windows_test:
    <<: *binary_windows_params
    parameters:
      build_environment:
        type: string
        default: ""
      executor:
        type: string
        default: "windows-medium-cpu-with-nvidia-cuda"
    executor: <<parameters.executor>>
    steps:
    - checkout
    - run:
        <<: *binary_checkout
    - run:
        <<: *binary_populate_env
    - run:
        name: Test
        no_output_timeout: "1h"
        command: |
          set -eux -o pipefail
          export TEST_NIGHTLY_PACKAGE=1
          script="/c/w/p/.circleci/scripts/binary_windows_test.sh"
          cat "$script"
          source "$script"

  anaconda_prune:
    parameters:
      packages:
        type: string
        description: "What packages are we pruning? (quoted, space-separated string. eg. 'pytorch', 'torchvision torchaudio', etc.)"
        default: "pytorch"
      channel:
        type: string
        description: "What channel are we pruning? (eq. pytorch-nightly)"
        default: "pytorch-nightly"
    docker:
      - image: continuumio/miniconda3
    environment:
      - PACKAGES: "<< parameters.packages >>"
      - CHANNEL: "<< parameters.channel >>"
    steps:
      - checkout
      - run:
          name: Install dependencies
          no_output_timeout: "1h"
          command: |
            conda install -yq anaconda-client
      - run:
          name: Prune packages
          no_output_timeout: "1h"
          command: |
              ANACONDA_API_TOKEN="${CONDA_PYTORCHBOT_TOKEN}" \
              scripts/release/anaconda-prune/run.sh

# There is currently no testing for libtorch TODO
#  binary_linux_libtorch_3.6m_cpu_test:
#    environment:
#      BUILD_ENVIRONMENT: "libtorch 3.6m cpu"
#    resource_class: gpu.medium
#    <<: *binary_linux_test
#
#  binary_linux_libtorch_3.6m_cu90_test:
#    environment:
#      BUILD_ENVIRONMENT: "libtorch 3.6m cu90"
#    resource_class: gpu.medium
#    <<: *binary_linux_test
#
